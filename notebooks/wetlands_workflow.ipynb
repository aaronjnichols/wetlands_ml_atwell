{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Wetlands GeoAI End-to-End Workflow\n",
        "\n",
        "This notebook walks through the full wetlands modelling pipeline:\n",
        "\n",
        "1. Acquire NAIP and Sentinel-2 composites for an area of interest (AOI) and build stack manifests.\n",
        "2. Prepare training data and fit the UNet semantic segmentation model.\n",
        "3. Run streaming inference on a hold-out AOI using the trained model.\n",
        "4. Compare predictions to National Wetlands Inventory (NWI) polygons on an interactive `leafmap` basemap.\n",
        "\n",
        "The workflow leans on reusable modules in `wetlands_ml_geoai` and is designed to stream large rasters from stack manifests without exhausting system memory.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prerequisites\n",
        "\n",
        "- Activate the project virtual environment and install dependencies (`pip install -r requirements.txt`).\n",
        "- Ensure the `geoai` and `leafmap` packages are installed (both are already listed in `requirements.txt`).\n",
        "- Provide AOI geometry files and wetlands labels locally (place them under the git-ignored `data/` directory).\n",
        "- Configure STAC access (public Element84 Sentinel-2 catalogue works without authentication).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import json\n",
        "import logging\n",
        "import os\n",
        "import sys\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Optional\n",
        "\n",
        "import geopandas as gpd\n",
        "import leafmap\n",
        "import numpy as np\n",
        "import rasterio\n",
        "from rasterio.features import shapes\n",
        "\n",
        "NOTEBOOK_ROOT = Path.cwd().resolve()\n",
        "SRC_PATH = NOTEBOOK_ROOT / \"src\"\n",
        "if not SRC_PATH.exists():\n",
        "    SRC_PATH = NOTEBOOK_ROOT.parent / \"src\"\n",
        "if SRC_PATH.exists() and str(SRC_PATH) not in sys.path:\n",
        "    sys.path.insert(0, str(SRC_PATH))\n",
        "\n",
        "from wetlands_ml_geoai.sentinel2.compositing import run_pipeline\n",
        "from wetlands_ml_geoai.training.unet import train_unet\n",
        "from wetlands_ml_geoai.inference.unet_stream import infer_manifest\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(levelname)s %(message)s\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Repository root: C:\\_code\\python\\wetlands_ml_codex\n",
            "Data directory: C:\\_code\\python\\wetlands_ml_codex\\data\n",
            "Artifacts directory: C:\\_code\\python\\wetlands_ml_codex\\outputs\n"
          ]
        }
      ],
      "source": [
        "# Resolve project directories (assumes the notebook lives under <repo_root>/notebooks)\n",
        "REPO_ROOT = Path.cwd().resolve()\n",
        "if not (REPO_ROOT / \"src\" / \"wetlands_ml_geoai\").exists():\n",
        "    REPO_ROOT = REPO_ROOT.parent\n",
        "\n",
        "DATA_DIR = REPO_ROOT / \"data\"\n",
        "ARTIFACTS_DIR = REPO_ROOT / \"outputs\"\n",
        "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "ARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"Repository root: {REPO_ROOT}\")\n",
        "print(f\"Data directory: {DATA_DIR}\")\n",
        "print(f\"Artifacts directory: {ARTIFACTS_DIR}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class PipelineConfig:\n",
        "    identifier: str\n",
        "    aoi: str\n",
        "    years: List[int]\n",
        "    output_dir: Path\n",
        "    labels_path: Path\n",
        "    wetlands_path: Optional[Path] = None\n",
        "    auto_download_naip: bool = True\n",
        "    auto_download_wetlands: bool = True\n",
        "    naip_year: Optional[int] = None\n",
        "    cloud_cover: float = 60.0\n",
        "    min_clear_obs: int = 3\n",
        "    seasons: tuple[str, ...] = (\"SPR\", \"SUM\", \"FAL\")\n",
        "    naip_max_items: Optional[int] = None\n",
        "    naip_preview: bool = False\n",
        "    mask_dilation: int = 0\n",
        "    naip_target_resolution: Optional[float] = None\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class TrainingConfig:\n",
        "    tiles_dir: Path\n",
        "    models_dir: Path\n",
        "    tile_size: int = 512\n",
        "    stride: int = 256\n",
        "    batch_size: int = 4\n",
        "    epochs: int = 10\n",
        "    architecture: str = \"unet\"\n",
        "    encoder_name: str = \"resnet34\"\n",
        "    learning_rate: float = 1e-3\n",
        "    weight_decay: float = 1e-4\n",
        "    val_split: float = 0.2\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class InferenceConfig:\n",
        "    window_size: int = 1024\n",
        "    overlap: int = 256\n",
        "    probability_threshold: float = 0.5\n",
        "    num_classes: int = 2\n",
        "    architecture: str = \"unet\"\n",
        "    encoder_name: str = \"resnet34\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- User configuration ---\n",
        "# Update these paths to point to your local data assets.\n",
        "TRAIN_AOI_CONFIG = PipelineConfig(\n",
        "    identifier=\"train_aoi\",\n",
        "    aoi=str(DATA_DIR / \"aoi\" / \"train_extent.gpkg\"),  # Replace with GPkg/WKT/GeoJSON/bbox\n",
        "    years=[2023],\n",
        "    output_dir=ARTIFACTS_DIR / \"train_aoi\",\n",
        "    labels_path=DATA_DIR / \"labels\" / \"train_wetlands.gpkg\",  # Provide NWI (or custom) training labels\n",
        "    wetlands_path=DATA_DIR / \"labels\" / \"train_wetlands.gpkg\",\n",
        "    auto_download_naip=True,\n",
        "    auto_download_wetlands=True,\n",
        "    naip_year=2021,\n",
        "    naip_max_items=12,\n",
        ")\n",
        "\n",
        "TEST_AOI_CONFIG = PipelineConfig(\n",
        "    identifier=\"test_aoi\",\n",
        "    aoi=str(DATA_DIR / \"aoi\" / \"test_extent.gpkg\"),\n",
        "    years=[2023],\n",
        "    output_dir=ARTIFACTS_DIR / \"test_aoi\",\n",
        "    labels_path=DATA_DIR / \"labels\" / \"test_wetlands.gpkg\",  # Optional: used for evaluation overlay\n",
        "    wetlands_path=DATA_DIR / \"labels\" / \"test_wetlands.gpkg\",\n",
        "    auto_download_naip=True,\n",
        "    auto_download_wetlands=True,\n",
        "    naip_year=2021,\n",
        "    naip_max_items=8,\n",
        ")\n",
        "\n",
        "TRAINING_CONFIG = TrainingConfig(\n",
        "    tiles_dir=ARTIFACTS_DIR / \"tiles\" / TRAIN_AOI_CONFIG.identifier,\n",
        "    models_dir=ARTIFACTS_DIR / \"models\" / TRAIN_AOI_CONFIG.identifier,\n",
        "    epochs=15,\n",
        "    batch_size=6,\n",
        ")\n",
        "\n",
        "INFERENCE_CONFIG = InferenceConfig(\n",
        "    window_size=1536,\n",
        "    overlap=384,\n",
        "    probability_threshold=0.6,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "RUN_TRAIN_PIPELINE = False   # Set to True to generate Sentinel-2 composites and stack manifests for training AOI\n",
        "RUN_TEST_PIPELINE = False    # Set to True to generate stack manifest for the inference AOI\n",
        "RUN_TRAINING = False         # Set to True to launch UNet training (may take hours on CPU)\n",
        "RUN_INFERENCE = False        # Set to True to run streaming inference on the test AOI\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ensure_paths_exist(config: PipelineConfig) -> None:\n",
        "    missing = []\n",
        "    if not Path(config.aoi).exists():\n",
        "        missing.append(config.aoi)\n",
        "    if config.wetlands_path and not config.wetlands_path.exists():\n",
        "        logging.warning(\"Wetlands GPkg missing at %s; auto-download is enabled.\" % config.wetlands_path)\n",
        "    if missing:\n",
        "        raise FileNotFoundError(\n",
        "            \"Missing required inputs: \" + \", \".join(missing)\n",
        "        )\n",
        "\n",
        "\n",
        "def run_stack_pipeline(cfg: PipelineConfig) -> None:\n",
        "    ensure_paths_exist(cfg)\n",
        "    cfg.output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    logging.info(\"Starting Sentinel-2 + NAIP pipeline for %s\", cfg.identifier)\n",
        "    run_pipeline(\n",
        "        aoi=cfg.aoi,\n",
        "        years=cfg.years,\n",
        "        output_dir=cfg.output_dir,\n",
        "        seasons=cfg.seasons,\n",
        "        cloud_cover=cfg.cloud_cover,\n",
        "        min_clear_obs=cfg.min_clear_obs,\n",
        "        auto_download_naip=cfg.auto_download_naip,\n",
        "        auto_download_naip_year=cfg.naip_year,\n",
        "        auto_download_naip_max_items=cfg.naip_max_items,\n",
        "        auto_download_naip_preview=cfg.naip_preview,\n",
        "        auto_download_wetlands=cfg.auto_download_wetlands,\n",
        "        wetlands_output_path=cfg.wetlands_path,\n",
        "        mask_dilation=cfg.mask_dilation,\n",
        "        naip_target_resolution=cfg.naip_target_resolution,\n",
        "    )\n",
        "    logging.info(\"Finished pipeline for %s\", cfg.identifier)\n",
        "\n",
        "\n",
        "def discover_manifests(directory: Path) -> List[Path]:\n",
        "    return sorted(directory.rglob(\"stack_manifest.json\"))\n",
        "\n",
        "\n",
        "def choose_model_checkpoint(models_dir: Path, preferred_name: str = \"best_model.pth\") -> Path:\n",
        "    candidate = models_dir / preferred_name\n",
        "    if candidate.exists():\n",
        "        return candidate\n",
        "    checkpoints = sorted(models_dir.glob(\"*.pth\"), key=lambda p: p.stat().st_mtime, reverse=True)\n",
        "    if not checkpoints:\n",
        "        raise FileNotFoundError(f\"No checkpoint files found under {models_dir}\")\n",
        "    logging.warning(\"Using most recent checkpoint: %s\", checkpoints[0])\n",
        "    return checkpoints[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if RUN_TRAIN_PIPELINE:\n",
        "    run_stack_pipeline(TRAIN_AOI_CONFIG)\n",
        "else:\n",
        "    logging.info(\"Skipping training AOI pipeline; set RUN_TRAIN_PIPELINE = True to execute.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if RUN_TEST_PIPELINE:\n",
        "    run_stack_pipeline(TEST_AOI_CONFIG)\n",
        "else:\n",
        "    logging.info(\"Skipping test AOI pipeline; set RUN_TEST_PIPELINE = True to execute.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_manifests = discover_manifests(TRAIN_AOI_CONFIG.output_dir)\n",
        "if not train_manifests:\n",
        "    logging.warning(\"No training manifests detected under %s\", TRAIN_AOI_CONFIG.output_dir)\n",
        "else:\n",
        "    for manifest in train_manifests:\n",
        "        logging.info(\"Training manifest -> %s\", manifest)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if RUN_TRAINING:\n",
        "    if not train_manifests:\n",
        "        raise RuntimeError(\"Training manifests missing. Generate them by enabling RUN_TRAIN_PIPELINE.\")\n",
        "    if not TRAIN_AOI_CONFIG.labels_path.exists():\n",
        "        raise FileNotFoundError(f\"Training labels not found at {TRAIN_AOI_CONFIG.labels_path}\")\n",
        "\n",
        "    TRAINING_CONFIG.tiles_dir.mkdir(parents=True, exist_ok=True)\n",
        "    TRAINING_CONFIG.models_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    logging.info(\"Launching UNet training with %s manifest(s).\", len(train_manifests))\n",
        "    train_unet(\n",
        "        labels_path=TRAIN_AOI_CONFIG.labels_path,\n",
        "        tiles_dir=TRAINING_CONFIG.tiles_dir,\n",
        "        models_dir=TRAINING_CONFIG.models_dir,\n",
        "        stack_manifest_path=train_manifests,\n",
        "        tile_size=TRAINING_CONFIG.tile_size,\n",
        "        stride=TRAINING_CONFIG.stride,\n",
        "        batch_size=TRAINING_CONFIG.batch_size,\n",
        "        epochs=TRAINING_CONFIG.epochs,\n",
        "        architecture=TRAINING_CONFIG.architecture,\n",
        "        encoder_name=TRAINING_CONFIG.encoder_name,\n",
        "        learning_rate=TRAINING_CONFIG.learning_rate,\n",
        "        weight_decay=TRAINING_CONFIG.weight_decay,\n",
        "        val_split=TRAINING_CONFIG.val_split,\n",
        "    )\n",
        "else:\n",
        "    logging.info(\"Skipping training; set RUN_TRAINING = True to launch model fitting.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_manifests = discover_manifests(TEST_AOI_CONFIG.output_dir)\n",
        "if not test_manifests:\n",
        "    logging.warning(\"No test manifests detected under %s\", TEST_AOI_CONFIG.output_dir)\n",
        "else:\n",
        "    for manifest in test_manifests:\n",
        "        logging.info(\"Test manifest -> %s\", manifest)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prediction_dir = ARTIFACTS_DIR / \"predictions\"\n",
        "prediction_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "prediction_raster = prediction_dir / f\"{TEST_AOI_CONFIG.identifier}_unet_prediction.tif\"\n",
        "\n",
        "if RUN_INFERENCE:\n",
        "    if not test_manifests:\n",
        "        raise RuntimeError(\"No test manifest found. Enable RUN_TEST_PIPELINE to generate one.\")\n",
        "    model_checkpoint = choose_model_checkpoint(TRAINING_CONFIG.models_dir)\n",
        "    logging.info(\"Using checkpoint: %s\", model_checkpoint)\n",
        "\n",
        "    infer_manifest(\n",
        "        manifest=test_manifests[0],\n",
        "        model_path=model_checkpoint,\n",
        "        output_path=prediction_raster,\n",
        "        window_size=INFERENCE_CONFIG.window_size,\n",
        "        overlap=INFERENCE_CONFIG.overlap,\n",
        "        num_channels=None,\n",
        "        architecture=INFERENCE_CONFIG.architecture,\n",
        "        encoder_name=INFERENCE_CONFIG.encoder_name,\n",
        "        num_classes=INFERENCE_CONFIG.num_classes,\n",
        "        probability_threshold=INFERENCE_CONFIG.probability_threshold,\n",
        "    )\n",
        "    logging.info(\"Inference complete -> %s\", prediction_raster)\n",
        "else:\n",
        "    logging.info(\"Skipping inference; set RUN_INFERENCE = True after training completes.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def raster_prediction_to_polygons(raster_path: Path, class_value: int = 1) -> gpd.GeoDataFrame:\n",
        "    if not raster_path.exists():\n",
        "        raise FileNotFoundError(f\"Prediction raster not found: {raster_path}\")\n",
        "    with rasterio.open(raster_path) as src:\n",
        "        mask = src.read(1)\n",
        "        results = []\n",
        "        for geom, value in shapes(mask.astype(np.uint8), transform=src.transform):\n",
        "            if int(value) == class_value:\n",
        "                results.append({\"geometry\": geom, \"properties\": {\"class\": int(value)}})\n",
        "        if not results:\n",
        "            logging.warning(\"No polygons extracted for class %s\", class_value)\n",
        "            return gpd.GeoDataFrame(columns=[\"geometry\"], geometry=\"geometry\", crs=src.crs)\n",
        "        gdf = gpd.GeoDataFrame.from_features(results, crs=src.crs)\n",
        "        return gdf\n",
        "\n",
        "\n",
        "def load_wetlands_labels(path: Path) -> gpd.GeoDataFrame:\n",
        "    if not path.exists():\n",
        "        raise FileNotFoundError(f\"Wetlands labels not found: {path}\")\n",
        "    gdf = gpd.read_file(path)\n",
        "    if gdf.crs is None:\n",
        "        logging.warning(\"Labels at %s lack CRS metadata; assuming EPSG:4326\", path)\n",
        "        gdf.set_crs(\"EPSG:4326\", inplace=True)\n",
        "    return gdf\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if prediction_raster.exists():\n",
        "    predicted_polys = raster_prediction_to_polygons(prediction_raster)\n",
        "    if predicted_polys.crs is not None and predicted_polys.crs.to_string() != \"EPSG:4326\":\n",
        "        predicted_polys = predicted_polys.to_crs(4326)\n",
        "\n",
        "    try:\n",
        "        reference_labels = load_wetlands_labels(TEST_AOI_CONFIG.labels_path)\n",
        "        if reference_labels.crs.to_string() != \"EPSG:4326\":\n",
        "            reference_labels = reference_labels.to_crs(4326)\n",
        "    except FileNotFoundError:\n",
        "        reference_labels = None\n",
        "        logging.warning(\"Reference wetlands not available; map will show predictions only.\")\n",
        "\n",
        "    if reference_labels is not None and not reference_labels.empty:\n",
        "        centroid = reference_labels.unary_union.centroid\n",
        "    elif not predicted_polys.empty:\n",
        "        centroid = predicted_polys.unary_union.centroid\n",
        "    else:\n",
        "        centroid = None\n",
        "\n",
        "    if centroid is None:\n",
        "        raise RuntimeError(\"Map extent unavailable; ensure predictions or labels are present.\")\n",
        "\n",
        "    map_center = (centroid.y, centroid.x)\n",
        "    m = leafmap.Map(center=map_center, zoom=12, measure_control=False)\n",
        "    m.add_basemap(\"Esri.WorldImagery\")\n",
        "\n",
        "    if reference_labels is not None and not reference_labels.empty:\n",
        "        m.add_gdf(\n",
        "            reference_labels,\n",
        "            layer_name=\"NWI Wetlands\",\n",
        "            style={\"color\": \"#3182bd\", \"fillColor\": \"#3182bd\", \"fillOpacity\": 0.5, \"weight\": 1},\n",
        "        )\n",
        "\n",
        "    if not predicted_polys.empty:\n",
        "        m.add_gdf(\n",
        "            predicted_polys,\n",
        "            layer_name=\"Predicted Wetlands\",\n",
        "            style={\"color\": \"#e377c2\", \"fillColor\": \"#e377c2\", \"fillOpacity\": 0.0, \"weight\": 2},\n",
        "        )\n",
        "\n",
        "    display(m)\n",
        "else:\n",
        "    logging.info(\"Prediction raster not yet generated. Run inference to create %s\", prediction_raster)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "\n",
        "- Validate that stack manifests include the expected 25-band (NAIP + 3-season Sentinel-2) configuration before training.\n",
        "- Inspect model checkpoints under `outputs/models/<identifier>` and track metrics logged by `geoai`.\n",
        "- After generating predictions, compute quantitative scores (IOU, precision/recall) by rasterizing ground-truth polygons onto the manifest grid.\n",
        "- Package results or derived layers in the `outputs/` directory; avoid committing rasters or GeoPackages to git.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv312",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
